Starting Hand Gesture Recognition Pipeline...
==================================================
Step 1: Loading and preprocessing data...
Loading dataset...
Processing subject 00...
Processing subject 01...
Processing subject 02...
Processing subject 03...
Processing subject 04...
Processing subject 05...
Processing subject 06...
Processing subject 07...
Processing subject 08...
Processing subject 09...
Total images loaded: 20000
Dataset shape: (20000, 128, 128, 1)
Number of unique gestures: 10
Gesture classes: ['01_palm' '02_l' '03_fist' '04_fist_moved' '05_thumb' '06_index' '07_ok'
 '08_palm_moved' '09_c' '10_down']
Step 2: Encoding labels...
Number of classes: 10
Classes: ['01_palm' '02_l' '03_fist' '04_fist_moved' '05_thumb' '06_index' '07_ok'
 '08_palm_moved' '09_c' '10_down']

Step 3: Splitting data...
Training set: (12800, 128, 128, 1)
Validation set: (3200, 128, 128, 1)
Test set: (4000, 128, 128, 1)

Step 4: Building and training model...
I0000 00:00:1751115745.317485      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0
Model summary:
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)  │ (None, 128, 128, 1)    │              0 │ -                      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d (Conv2D)           │ (None, 64, 64, 64)     │          3,200 │ input_layer[0][0]      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization       │ (None, 64, 64, 64)     │            256 │ conv2d[0][0]           │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation (Activation)   │ (None, 64, 64, 64)     │              0 │ batch_normalization[0… │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ max_pooling2d             │ (None, 32, 32, 64)     │              0 │ activation[0][0]       │
│ (MaxPooling2D)            │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_1 (Conv2D)         │ (None, 32, 32, 64)     │         36,928 │ max_pooling2d[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_1     │ (None, 32, 32, 64)     │            256 │ conv2d_1[0][0]         │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_1 (Activation) │ (None, 32, 32, 64)     │              0 │ batch_normalization_1… │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_2 (Conv2D)         │ (None, 32, 32, 64)     │         36,928 │ activation_1[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_2     │ (None, 32, 32, 64)     │            256 │ conv2d_2[0][0]         │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ add (Add)                 │ (None, 32, 32, 64)     │              0 │ batch_normalization_2… │
│                           │                        │                │ max_pooling2d[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_2 (Activation) │ (None, 32, 32, 64)     │              0 │ add[0][0]              │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_3 (Conv2D)         │ (None, 32, 32, 64)     │         36,928 │ activation_2[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_3     │ (None, 32, 32, 64)     │            256 │ conv2d_3[0][0]         │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_3 (Activation) │ (None, 32, 32, 64)     │              0 │ batch_normalization_3… │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_4 (Conv2D)         │ (None, 32, 32, 64)     │         36,928 │ activation_3[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_4     │ (None, 32, 32, 64)     │            256 │ conv2d_4[0][0]         │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ add_1 (Add)               │ (None, 32, 32, 64)     │              0 │ batch_normalization_4… │
│                           │                        │                │ activation_2[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_4 (Activation) │ (None, 32, 32, 64)     │              0 │ add_1[0][0]            │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_5 (Conv2D)         │ (None, 16, 16, 128)    │         73,856 │ activation_4[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_5     │ (None, 16, 16, 128)    │            512 │ conv2d_5[0][0]         │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_5 (Activation) │ (None, 16, 16, 128)    │              0 │ batch_normalization_5… │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_6 (Conv2D)         │ (None, 16, 16, 128)    │        147,584 │ activation_5[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_7 (Conv2D)         │ (None, 16, 16, 128)    │          8,320 │ activation_4[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_6     │ (None, 16, 16, 128)    │            512 │ conv2d_6[0][0]         │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_7     │ (None, 16, 16, 128)    │            512 │ conv2d_7[0][0]         │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ add_2 (Add)               │ (None, 16, 16, 128)    │              0 │ batch_normalization_6… │
│                           │                        │                │ batch_normalization_7… │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_6 (Activation) │ (None, 16, 16, 128)    │              0 │ add_2[0][0]            │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_8 (Conv2D)         │ (None, 16, 16, 128)    │        147,584 │ activation_6[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_8     │ (None, 16, 16, 128)    │            512 │ conv2d_8[0][0]         │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_7 (Activation) │ (None, 16, 16, 128)    │              0 │ batch_normalization_8… │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_9 (Conv2D)         │ (None, 16, 16, 128)    │        147,584 │ activation_7[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_9     │ (None, 16, 16, 128)    │            512 │ conv2d_9[0][0]         │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ add_3 (Add)               │ (None, 16, 16, 128)    │              0 │ batch_normalization_9… │
│                           │                        │                │ activation_6[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_8 (Activation) │ (None, 16, 16, 128)    │              0 │ add_3[0][0]            │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_10 (Conv2D)        │ (None, 8, 8, 256)      │        295,168 │ activation_8[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_10    │ (None, 8, 8, 256)      │          1,024 │ conv2d_10[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_9 (Activation) │ (None, 8, 8, 256)      │              0 │ batch_normalization_1… │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_11 (Conv2D)        │ (None, 8, 8, 256)      │        590,080 │ activation_9[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_12 (Conv2D)        │ (None, 8, 8, 256)      │         33,024 │ activation_8[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_11    │ (None, 8, 8, 256)      │          1,024 │ conv2d_11[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_12    │ (None, 8, 8, 256)      │          1,024 │ conv2d_12[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ add_4 (Add)               │ (None, 8, 8, 256)      │              0 │ batch_normalization_1… │
│                           │                        │                │ batch_normalization_1… │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_10             │ (None, 8, 8, 256)      │              0 │ add_4[0][0]            │
│ (Activation)              │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_13 (Conv2D)        │ (None, 8, 8, 256)      │        590,080 │ activation_10[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_13    │ (None, 8, 8, 256)      │          1,024 │ conv2d_13[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_11             │ (None, 8, 8, 256)      │              0 │ batch_normalization_1… │
│ (Activation)              │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d_14 (Conv2D)        │ (None, 8, 8, 256)      │        590,080 │ activation_11[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ batch_normalization_14    │ (None, 8, 8, 256)      │          1,024 │ conv2d_14[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ add_5 (Add)               │ (None, 8, 8, 256)      │              0 │ batch_normalization_1… │
│                           │                        │                │ activation_10[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ activation_12             │ (None, 8, 8, 256)      │              0 │ add_5[0][0]            │
│ (Activation)              │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ global_average_pooling2d  │ (None, 256)            │              0 │ activation_12[0][0]    │
│ (GlobalAveragePooling2D)  │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ dropout (Dropout)         │ (None, 256)            │              0 │ global_average_poolin… │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ dense (Dense)             │ (None, 512)            │        131,584 │ dropout[0][0]          │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ dropout_1 (Dropout)       │ (None, 512)            │              0 │ dense[0][0]            │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ dense_1 (Dense)           │ (None, 10)             │          5,130 │ dropout_1[0][0]        │
└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘
 Total params: 2,919,946 (11.14 MB)
 Trainable params: 2,915,466 (11.12 MB)
 Non-trainable params: 4,480 (17.50 KB)
Training the model...
Epoch 1/100
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1751115761.887102     100 service.cc:148] XLA service 0x7a7844001fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1751115761.888045     100 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0
I0000 00:00:1751115763.260676     100 cuda_dnn.cc:529] Loaded cuDNN version 90300
  5/400 ━━━━━━━━━━━━━━━━━━━━ 15s 38ms/step - accuracy: 0.0919 - loss: 2.6277 
I0000 00:00:1751115770.393502     100 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
400/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.5576 - loss: 1.2216
Epoch 1: val_accuracy improved from -inf to 0.19563, saving model to best_gesture_model.h5
400/400 ━━━━━━━━━━━━━━━━━━━━ 43s 49ms/step - accuracy: 0.5581 - loss: 1.2202 - val_accuracy: 0.1956 - val_loss: 7.5974 - learning_rate: 0.0010
Epoch 2/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9436 - loss: 0.1688
Epoch 2: val_accuracy improved from 0.19563 to 0.69531, saving model to best_gesture_model.h5
400/400 ━━━━━━━━━━━━━━━━━━━━ 18s 44ms/step - accuracy: 0.9437 - loss: 0.1687 - val_accuracy: 0.6953 - val_loss: 2.1578 - learning_rate: 0.0010
Epoch 3/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9659 - loss: 0.1078
Epoch 3: val_accuracy improved from 0.69531 to 0.90125, saving model to best_gesture_model.h5
400/400 ━━━━━━━━━━━━━━━━━━━━ 18s 44ms/step - accuracy: 0.9660 - loss: 0.1077 - val_accuracy: 0.9013 - val_loss: 0.3027 - learning_rate: 0.0010
Epoch 4/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.9758 - loss: 0.0863
Epoch 4: val_accuracy did not improve from 0.90125
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 43ms/step - accuracy: 0.9759 - loss: 0.0862 - val_accuracy: 0.8556 - val_loss: 0.4628 - learning_rate: 0.0010
Epoch 5/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9859 - loss: 0.0504
Epoch 5: val_accuracy did not improve from 0.90125
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 44ms/step - accuracy: 0.9859 - loss: 0.0504 - val_accuracy: 0.8947 - val_loss: 0.3903 - learning_rate: 0.0010
Epoch 6/100
400/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9807 - loss: 0.0551
Epoch 6: val_accuracy did not improve from 0.90125
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 44ms/step - accuracy: 0.9807 - loss: 0.0551 - val_accuracy: 0.4834 - val_loss: 2.7528 - learning_rate: 0.0010
Epoch 7/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.9883 - loss: 0.0413
Epoch 7: val_accuracy improved from 0.90125 to 0.97750, saving model to best_gesture_model.h5
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 44ms/step - accuracy: 0.9883 - loss: 0.0413 - val_accuracy: 0.9775 - val_loss: 0.0655 - learning_rate: 0.0010
Epoch 8/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9900 - loss: 0.0332
Epoch 8: val_accuracy improved from 0.97750 to 1.00000, saving model to best_gesture_model.h5
400/400 ━━━━━━━━━━━━━━━━━━━━ 18s 46ms/step - accuracy: 0.9900 - loss: 0.0332 - val_accuracy: 1.0000 - val_loss: 6.4442e-04 - learning_rate: 0.0010
Epoch 9/100
400/400 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9921 - loss: 0.0254
Epoch 9: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 18s 45ms/step - accuracy: 0.9921 - loss: 0.0254 - val_accuracy: 0.9131 - val_loss: 0.2596 - learning_rate: 0.0010
Epoch 10/100
400/400 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9911 - loss: 0.0350
Epoch 10: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 18s 44ms/step - accuracy: 0.9911 - loss: 0.0351 - val_accuracy: 0.9869 - val_loss: 0.0318 - learning_rate: 0.0010
Epoch 11/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9929 - loss: 0.0235
Epoch 11: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 43ms/step - accuracy: 0.9929 - loss: 0.0236 - val_accuracy: 0.6159 - val_loss: 2.3026 - learning_rate: 0.0010
Epoch 12/100
400/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9920 - loss: 0.0339
Epoch 12: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 43ms/step - accuracy: 0.9920 - loss: 0.0339 - val_accuracy: 0.9991 - val_loss: 0.0055 - learning_rate: 0.0010
Epoch 13/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9909 - loss: 0.0327
Epoch 13: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 43ms/step - accuracy: 0.9909 - loss: 0.0327 - val_accuracy: 0.9966 - val_loss: 0.0085 - learning_rate: 0.0010
Epoch 14/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9960 - loss: 0.0168
Epoch 14: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 43ms/step - accuracy: 0.9960 - loss: 0.0168 - val_accuracy: 0.9975 - val_loss: 0.0077 - learning_rate: 0.0010
Epoch 15/100
400/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9931 - loss: 0.0283
Epoch 15: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 43ms/step - accuracy: 0.9931 - loss: 0.0283 - val_accuracy: 0.9972 - val_loss: 0.0191 - learning_rate: 0.0010
Epoch 16/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9941 - loss: 0.0191
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.

Epoch 16: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 44ms/step - accuracy: 0.9941 - loss: 0.0191 - val_accuracy: 0.9684 - val_loss: 0.0942 - learning_rate: 0.0010
Epoch 17/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9973 - loss: 0.0128
Epoch 17: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 44ms/step - accuracy: 0.9973 - loss: 0.0128 - val_accuracy: 0.9987 - val_loss: 0.0041 - learning_rate: 5.0000e-04
Epoch 18/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.9985 - loss: 0.0053
Epoch 18: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 43ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 1.8841e-04 - learning_rate: 5.0000e-04
Epoch 19/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9983 - loss: 0.0070
Epoch 19: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 18s 44ms/step - accuracy: 0.9983 - loss: 0.0070 - val_accuracy: 0.9981 - val_loss: 0.0088 - learning_rate: 5.0000e-04
Epoch 20/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9985 - loss: 0.0064
Epoch 20: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 43ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.9997 - val_loss: 5.9776e-04 - learning_rate: 5.0000e-04
Epoch 21/100
400/400 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9978 - loss: 0.0095
Epoch 21: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 43ms/step - accuracy: 0.9978 - loss: 0.0096 - val_accuracy: 0.9987 - val_loss: 0.0021 - learning_rate: 5.0000e-04
Epoch 22/100
400/400 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.9965 - loss: 0.0106
Epoch 22: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 42ms/step - accuracy: 0.9965 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 1.8615e-04 - learning_rate: 5.0000e-04
Epoch 23/100
399/400 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.9982 - loss: 0.0066
Epoch 23: val_accuracy did not improve from 1.00000
400/400 ━━━━━━━━━━━━━━━━━━━━ 17s 43ms/step - accuracy: 0.9982 - loss: 0.0066 - val_accuracy: 0.9997 - val_loss: 0.0019 - learning_rate: 5.0000e-04
Epoch 23: early stopping
Restoring model weights from the end of the best epoch: 8.
Step 5: Evaluating model...
125/125 ━━━━━━━━━━━━━━━━━━━━ 2s 6ms/step
Test Accuracy: 0.8590

Classification Report:
               precision    recall  f1-score   support

      01_palm       0.70      0.83      0.76       400
         02_l       1.00      0.92      0.96       400
      03_fist       1.00      0.26      0.41       400
04_fist_moved       0.62      0.81      0.70       400
     05_thumb       0.92      0.77      0.84       400
     06_index       1.00      1.00      1.00       400
        07_ok       0.99      1.00      1.00       400
08_palm_moved       0.86      1.00      0.92       400
         09_c       1.00      1.00      1.00       400
      10_down       0.77      1.00      0.87       400

     accuracy                           0.86      4000
    macro avg       0.88      0.86      0.85      4000
 weighted avg       0.88      0.86      0.85      4000

Generated Output Files:
📊 model_results_summary_20250628_130944.json - Overall model performance summary
📋 classification_report_20250628_130944.json - Detailed per-class metrics
📈 training_history_20250628_130944.csv - Training/validation curves data
🎯 test_predictions_20250628_130944.csv - Individual test predictions with probabilities
🔄 confusion_matrix_20250628_130944.csv - Confusion matrix data
📊 per_class_performance_20250628_130944.csv - Per-class detailed performance
🏗️ model_architecture_20250628_130944.txt - Model architecture details
📊 training_plots_20250628_130944.png - Training history visualization
🔥 confusion_matrix_20250628_130944.png - Confusion matrix heatmap
📖 README_20250628_130944.md - Complete documentation
🤖 hand_gesture_recognition_model.h5 - Keras model file (H5 format)
🤖 hand_gesture_recognition_model.keras - Keras model file (native format)
🤖 gesture_model_savedmodel/ - TensorFlow SavedModel format
🏷️ label_encoder.pkl - Label encoder for predictions
All output files generated successfully!
Final test accuracy: 0.8590
